
# Scraper de Agencias de Viaje en Argentina üá¶üá∑

Este proyecto permite extraer informaci√≥n de agencias de viaje registradas en [https://www.agenciasdeviajes.ar/](https://www.agenciasdeviajes.ar/) utilizando `Playwright` en un entorno como Google Colab.

## üìå Descripci√≥n

El script automatiza la navegaci√≥n por la p√°gina oficial de agencias de viaje, buscando por provincia y extrayendo informaci√≥n √∫til como:

- Nombre de la agencia
- Tel√©fono
- Correo electr√≥nico
- Localidad
- Provincia

Los datos se guardan autom√°ticamente en:

- Un archivo `.CSV` (local)
- Un archivo `.XLSX` en Google Drive

Existen dos versiones de archivos con extensi√≥n `.py`:

- `web_scraping-rnav.py`: Versi√≥n para ejecutar en la PC, sin conexi√≥n a Google Drive
- `web_scraping-rnav_colab-jupiter.py`: Versi√≥n para ejecutar en Google Colab o Jupyter

## üß∞ Tecnolog√≠as utilizadas

- `Playwright` ‚Üí Para automatizar la navegaci√≥n por la web
- `asyncio` ‚Üí Para gestionar tareas as√≠ncronas
- `pandas` ‚Üí Para exportar los datos a Excel
- `google.colab` ‚Üí Para montar Google Drive
- `nest_asyncio` ‚Üí Permite ejecutar bucles as√≠ncronos dentro de notebooks de Colab
- `email-validator` ‚Üí Para validar correos electr√≥nicos

## ‚öôÔ∏è Requisitos previos

Antes de ejecutar el script, asegurate de instalar y configurar:

```bash
pip install playwright nest_asyncio pandas email-validator
playwright install
```

Adem√°s, mont√° Google Drive en Colab con:

```python
from google.colab import drive
drive.mount('/content/drive')
```

## üß† C√≥mo funciona

1. El usuario ingresa la **provincia** a consultar.
2. El navegador se abre en segundo plano y navega al sitio.
3. Se escribe la provincia en el buscador.
4. Se recorren todas las p√°ginas de resultados.
5. Por cada agencia, se extraen los datos desde su bloque HTML.
6. Si aparece un **modal emergente (pop-up)**, se cierra autom√°ticamente para no interrumpir la navegaci√≥n.
7. Antes de guardar los resultados, se realiza un proceso de normalizaci√≥n de correos.
8. Finalmente, se guardan los resultados en CSV y XLXS(opcional).

## ‚úâÔ∏è Normalizaci√≥n y correcci√≥n de correos electr√≥nicos

Durante el proceso de scraping, los correos electr√≥nicos extra√≠dos son normalizados autom√°ticamente para corregir errores comunes como:

- Faltante del s√≠mbolo `@`
- Dominios incompletos como `gmail` en lugar de `@gmail.com`
- Sustituciones como `(at)`, `[arroba]`, etc.
- Caracteres especiales no v√°lidos

Esta normalizaci√≥n se realiza con la funci√≥n:

```python
normalizar_correo(correo: str) -> str
```

Si un correo no puede ser validado autom√°ticamente, se almacena junto con el nombre de la agencia para su revisi√≥n posterior.

---

### üõ† Correcci√≥n manual de correos

Al finalizar el scraping, si hay correos inv√°lidos, se listan y se ofrece la opci√≥n de corregirlos manualmente con:

```python
corregir_correos_invalidos()
```

Este proceso permite:

- Ver el nombre de la agencia asociada al correo inv√°lido
- Ingresar una correcci√≥n v√°lida
- Validar autom√°ticamente el nuevo correo
- Actualizar el archivo CSV con la correcci√≥n correspondiente

---

### ‚ö†Ô∏è Aviso al usuario antes de guardar

En caso de que **uno o m√°s correos no puedan ser normalizados autom√°ticamente**, el sistema lo informar√° al usuario.  
Antes de guardar el archivo final, se ofrecer√° la posibilidad de **modificarlos manualmente**, asegurando as√≠ que la informaci√≥n quede lo m√°s completa y precisa posible.

## ‚öôÔ∏è Manejo del Modal en el Scraping

Durante el scraping, la web puede mostrar un modal (ventana emergente) que interrumpe el proceso. Para evitar esto, el script incluye un bloque para cerrar autom√°ticamente cualquier modal detectado:

```python
await page.evaluate("""
    () => {
        const modal = document.querySelector('[role=dialog]');
        if (modal) {
            window.dispatchEvent(new CustomEvent('close-modal', { detail: { id: 'video1year' }}));
        }
    }
""")
```

Esto permite que el scraping contin√∫e sin interrupciones.

## üì¶ Ejecuci√≥n del script

```python
await scrapear_agencias_completo()
```

---

## üìú Licencia

Este proyecto se publica con fines educativos y de pr√°ctica.

## üìå Contacto

ecarracedo@gmail.com

## üìã Changelog

### [1.4.0] - 2025-04-16  
#### A√±adido  
- Asociaci√≥n de correos inv√°lidos con el nombre de la agencia durante el scraping  
- Opci√≥n para corregir manualmente correos inv√°lidos, identificando claramente a qu√© agencia pertenecen  
- Validaci√≥n mejorada de correos ingresados manualmente  
- Actualizaci√≥n autom√°tica del archivo CSV con correcciones  
- Mejora del formato de salida al mostrar correos inv√°lidos (m√°s legible y profesional)

#### Corregido  
- Problema donde el nombre de la agencia no se guardaba correctamente al detectar un correo inv√°lido

### [1.3.0] - 2024-03-21  
#### A√±adido  
- Mejoras en la normalizaci√≥n de correos electr√≥nicos:
  - Detecci√≥n y correcci√≥n de falta de @ en dominios comunes
  - Detecci√≥n y correcci√≥n de falta de .com en dominios comunes
  - Reemplazo de s√≠mbolos comunes que se usan en lugar de @
  - Mejor manejo de caracteres especiales

### [1.2.0] - 2024-03-21  
#### A√±adido  
- Normalizaci√≥n de correos electr√≥nicos (eliminaci√≥n de caracteres especiales y tildes)

### [1.1.0] - 2024-03-21  
#### A√±adido  
- Men√∫ interactivo con todas las provincias de Argentina  
- Opci√≥n para volver a ejecutar el script con otra provincia  
- Mejor manejo de errores en la selecci√≥n de provincias

### [1.0.0] - 2024-03-20  
#### A√±adido  
- Versi√≥n inicial del scraper  
- Extracci√≥n de datos de agencias de viaje  
- Guardado en formato CSV y Excel  
- Manejo autom√°tico de modales emergentes
