# Scraper de Agencias de Viaje en Argentina üá¶üá∑

Este proyecto permite extraer informaci√≥n de agencias de viaje registradas en [https://www.agenciasdeviajes.ar/](https://www.agenciasdeviajes.ar/) utilizando `Playwright` en un entorno como Google Colab.

## üìå Descripci√≥n

El script automatiza la navegaci√≥n por la p√°gina oficial de agencias de viaje, buscando por provincia y extrayendo informaci√≥n √∫til como:

- Nombre de la agencia
- Tel√©fono
- Correo electr√≥nico
- Localidad
- Provincia

Los datos se guardan autom√°ticamente en:

- Un archivo `.CSV` (local)
- Un archivo `.XLSX` en Google Drive

Existe dos versiones de archivos con extension py:

- `web_scraping-rnav.py`: Es una version para ejecutar en la pc, sin la conexion a Google Drive
- `web_scraping-rnav_colab-jupiter.py`: Es una version para ejecutar en Google Colab o en Jupyter

## üß∞ Tecnolog√≠as utilizadas

- `Playwright` ‚Üí Para automatizar la navegaci√≥n por la web
- `asyncio` ‚Üí Para gestionar tareas as√≠ncronas
- `pandas` ‚Üí Para exportar los datos a Excel
- `google.colab` ‚Üí Para montar Google Drive
- `nest_asyncio` ‚Üí Permite ejecutar bucles as√≠ncronos dentro de notebooks de Colab

## ‚öôÔ∏è Requisitos previos

Antes de ejecutar el script, asegurate de instalar y configurar:

```bash
pip install playwright nest_asyncio pandas
playwright install
```

Adem√°s, mont√° Google Drive en Colab con:

```python
from google.colab import drive
drive.mount('/content/drive')
```

## üß† C√≥mo funciona

1. El usuario ingresa la **provincia** a consultar.
2. El navegador se abre en segundo plano y navega al sitio.
3. Se escribe la provincia en el buscador.
4. Se recorren todas las p√°ginas de resultados.
5. Por cada agencia, se extraen los datos desde su bloque HTML.
6. Si aparece un **modal emergente (pop-up)**, se cierra autom√°ticamente para no interrumpir la navegaci√≥n.
7. Finalmente, se guardan los resultados en CSV y XLSX.

## ‚öôÔ∏è Manejo del Modal en el Scraping

En el proceso de scraping, a veces la p√°gina web puede mostrar un modal (una ventana emergente) que bloquea el acceso al contenido o interrumpe la navegaci√≥n. Los modales son com√∫nmente utilizados para mostrar mensajes de bienvenida, publicidad o notificaciones. Para asegurarnos de que el scraper pueda continuar su ejecuci√≥n sin problemas, se implement√≥ un manejo especial para detectar y cerrar estos modales si est√°n presentes.

---

### **¬øQu√© hace el c√≥digo con respecto a los modales?**

En el c√≥digo, se utiliza la funci√≥n `evaluate` para verificar si existe un modal abierto y cerrarlo. Este proceso se realiza de la siguiente manera:

```python
# Cerramos el modal (si est√° abierto) para poder seguir navegando
await page.evaluate("""
    () => {
        const modal = document.querySelector('[role=dialog]');  // Buscamos el modal en el DOM
        if (modal) {  // Si existe el modal
            window.dispatchEvent(new CustomEvent('close-modal', { detail: { id: 'video1year' }}));  // Cerramos el modal
        }
    }
""")
```

---

#### **Explicaci√≥n del c√≥digo**:

1. **`document.querySelector('[role=dialog]')`**  
   Se utiliza este selector para buscar un modal en el DOM de la p√°gina web. El atributo `[role=dialog]` se usa com√∫nmente para representar modales, ya que su funci√≥n sem√°ntica es mostrar un cuadro de di√°logo.

2. **`window.dispatchEvent(new CustomEvent('close-modal'))`**  
   Si el modal es encontrado, se env√≠a un evento de cierre utilizando `dispatchEvent` para simular la acci√≥n de cerrar el modal. Esto permite que el scraper contin√∫e trabajando sin ser bloqueado por el modal.

3. **¬øPor qu√© es importante esto?**  
   Sin este manejo del modal, si la p√°gina presenta un modal, podr√≠a bloquear la extracci√≥n de los datos o interrumpir la navegaci√≥n hacia la siguiente p√°gina. Esto se evita cerrando autom√°ticamente el modal si est√° presente.


## üì¶ Ejecuci√≥n del script

```python
await scrapear_agencias_completo()
```
# üß† Explicaci√≥n l√≠nea por l√≠nea del c√≥digo

Este script automatiza el scraping de agencias de viajes desde [https://www.agenciasdeviajes.ar](https://www.agenciasdeviajes.ar) usando `Playwright` y se ejecuta perfectamente en Google Colab.

---

```python
import asyncio                              # Para manejar tareas as√≠ncronas
import csv                                  # Para guardar los datos como archivo CSV
import pandas as pd                         # Para manipulaci√≥n de datos y exportaci√≥n a Excel
from google.colab import drive              # Para montar Google Drive en Colab
from playwright.async_api import async_playwright, TimeoutError  # Librer√≠a principal de automatizaci√≥n web
```

```python
drive.mount('/content/drive')              # Monta Google Drive para poder guardar archivos directamente all√≠
```

---

### Funci√≥n principal

```python
async def scrapear_agencias_completo():
    provincia = input("üìç Ingres√° la provincia que quer√©s buscar: ").strip()  # Solicita al usuario la provincia a buscar
```

```python
    async with async_playwright() as p:                      # Inicializa Playwright
        browser = await p.chromium.launch(headless=True)     # Lanza navegador Chromium en modo sin cabeza
        context = await browser.new_context()                # Crea nuevo contexto (como una pesta√±a aislada)
        page = await context.new_page()                      # Abre nueva p√°gina
```

---

### Ir a la web y buscar

```python
        await page.goto("https://www.agenciasdeviajes.ar/#buscador", timeout=30000)  # Carga la p√°gina
        await page.wait_for_selector("input[placeholder*='Ciudad o Provincia']", timeout=20000)
        await page.fill("input[placeholder*='Ciudad o Provincia']", provincia)        # Escribe la provincia
        await page.wait_for_timeout(2000)                                             # Espera a que cargue
        await page.wait_for_selector("h3.text-lg", timeout=20000)                    # Espera que aparezcan los resultados
```

---

### Extraer resultados

```python
        agencias = []             # Lista donde se guardar√°n los datos
        pagina = 1                # Contador de p√°ginas

        while True:
            h3_agencias = await page.query_selector_all("h3.text-lg")  # Encuentra los t√≠tulos (nombres de agencias)
```

```python
            for h3 in h3_agencias:
                nombre = await h3.inner_text()      # Extrae el nombre de la agencia
                telefono = ""
                correo = ""
                localidad = ""

                contenedor = await h3.evaluate_handle("node => node.parentElement.parentElement")  # Va al contenedor de info
                contenedor_element = contenedor.as_element()

                if contenedor_element:
                    parrafos = await contenedor_element.query_selector_all("p.leading-relaxed.text-sm")  # Busca los p√°rrafos de datos

                    for p in parrafos:
                        texto = await p.inner_text()
                        if "Tel√©fono:" in texto:
                            telefono = texto.replace("Tel√©fono:", "").strip()
                        if "Correo electr√≥nico:" in texto:
                            correo = texto.replace("Correo electr√≥nico:", "").strip()
                        if "Localidad:" in texto:
                            localidad = texto.replace("Localidad:", "").strip()
```

```python
                agencias.append({                               # Agrega los datos a la lista
                    "nombre": nombre,
                    "telefono": telefono,
                    "correo": correo,
                    "localidad": localidad,
                    "provincia": provincia
                })
```

---

### Cierre de modal (si aparece)

```python
            await page.evaluate("""                            # Ejecuta c√≥digo JavaScript para cerrar un modal emergente
                () => {
                    const modal = document.querySelector('[role=dialog]');
                    if (modal) {
                        window.dispatchEvent(new CustomEvent('close-modal', { detail: { id: 'video1year' }}));
                    }
                }
            """)
```

---

### Navegaci√≥n entre p√°ginas

```python
            siguiente = page.locator("button[dusk='nextPage.after']")    # Busca el bot√≥n "Siguiente"
            if await siguiente.count() == 0 or not await siguiente.is_enabled():  # Si no hay m√°s p√°ginas
                break

            await siguiente.scroll_into_view_if_needed()    # Asegura que el bot√≥n est√© visible
            await siguiente.click()                         # Hace clic en "Siguiente"
            await page.wait_for_timeout(2500)               # Espera a que cargue
            pagina += 1
```

---

### Guardado de datos

```python
        await browser.close()   # Cierra el navegador
```

```python
        # Guardar CSV local
        csv_filename = f"{provincia.lower().replace(' ', '_')}_agencias_viaje.csv"
        with open(csv_filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["nombre", "telefono", "correo", "localidad", "provincia"])
            writer.writeheader()
            writer.writerows(agencias)
```

```python
        # Guardar Excel en Drive
        df = pd.DataFrame(agencias)
        xlsx_path = f"/content/drive/MyDrive/EC/WebScraping/RNAV/{provincia.lower().replace(' ', '_')}_agencias_viaje.xlsx"
        df.to_excel(xlsx_path, index=False)
```

---

### Manejador de errores

```python
    except KeyboardInterrupt:
        print("‚ùå Ejecuci√≥n interrumpida por el usuario.")
    except TimeoutError as e:
        print(f"‚ùå Timeout alcanzado: {e}")
    except Exception as e:
        print(f"‚ö†Ô∏è Ocurri√≥ un error inesperado: {e}")
```

---

### Ejecuci√≥n

```python
await scrapear_agencias_completo()   # Ejecuta todo el proceso
```

---


## üìú Licencia

Este proyecto se publica con fines educativos y de pr√°ctica.

## üìå Contacto

ecarracedo@gmail.com